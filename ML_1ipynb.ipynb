{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.parameter is a value that a machine learning model learns from the training data. These parameters define how the model makes predictions. During training, the model adjusts these parameters to minimize errors and improve accuracy\n"
      ],
      "metadata": {
        "id": "R_w5JNDbzAnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Correlation measures the strength and direction of a linear relationship between two variables. It ranges from -1 perfect negative correlation to 1 perfect positive correlation. A value of 0 indicates no linear relationship\n",
        "Negative correlation occurs when one variable increases as the other decreases. Correlation refers to a statistical relationship between two variables, indicating how closely they move together. It does not imply causation. Correlation can be positive (variables move together), negative (variables move in opposite directions), or zero (no linear relationship)\n",
        "\n"
      ],
      "metadata": {
        "id": "o7V_dkSY0uwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Machine Learning (ML) is a subset of Artificial Intelligence (AI) where systems learn from data to make predictions or decisions without being explicitly programmed"
      ],
      "metadata": {
        "id": "Xhkws7Dv1yyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "Loss is a measure of how well or poorly a machine learning model is performing. It calculates the difference between the model’s predictions and the actual values. A lower loss value indicates a better model, while a higher loss suggests poor performance.\n",
        "The loss value measures the difference between a model's predictions and actual outcomes. Lower loss values indicate better model performance. By minimizing loss during training, models can improve their accuracy and generalization capabilities"
      ],
      "metadata": {
        "id": "BXqz8oO9tfdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What Are Continuous and Categorical Variables?\n",
        "\n",
        "Continuous variables are numeric and can take any value within a range (e.g., height, weight).\n",
        "\n",
        "Categorical variables represent discrete categories or labels (e.g., colors, yes/no responses)."
      ],
      "metadata": {
        "id": "pmu_CLIJ2Ggi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "Handling categorical variables involves converting them into numerical formats that models can process. Common techniques include:\n",
        "\n",
        "One-Hot Encoding: Each category becomes a binary feature.\n",
        "\n",
        "Label Encoding: Assigns a unique integer to each category.\n",
        "\n",
        "Ordinal Encoding: Used when categories have a natural order."
      ],
      "metadata": {
        "id": "K6T7PjJswnqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What do you mean by training and testing a dataset?\n",
        "\n",
        "Training Set: Used to train the model by fitting parameters.\n",
        "\n",
        "Testing Set: Used to evaluate the model's performance on unseen data."
      ],
      "metadata": {
        "id": "trgNTUvM37ag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What is sklearn.preprocessing?\n",
        "\n",
        "A module in Python's scikit-learn library that provides utilities for feature scaling, encoding categorical variables, and data transformation."
      ],
      "metadata": {
        "id": "exww_XF14FyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.What is a Test set?\n",
        "A subset of data reserved for evaluating the model's performance after training."
      ],
      "metadata": {
        "id": "fxnLeSmN4KFi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?\n",
        "\n",
        "Data splitting in Python can be done using train_test_split from sklearn.model_selection.\n",
        "\n",
        "Problem Definition: Identify the task (classification, regression).\n",
        "\n",
        "Data Collection: Gather relevant data.\n",
        "\n",
        "Exploratory Data Analysis (EDA): Understand data distributions and relationships.\n",
        "\n",
        "Data Preprocessing: Clean and transform data.\n",
        "\n",
        "Model Selection: Choose appropriate algorithms.\n",
        "\n",
        "Training and Evaluation: Train models and assess performance.\n",
        "\n",
        "Hyperparameter Tuning: Optimize model configurations.\n",
        "\n",
        "Deployment: Implement the model in production."
      ],
      "metadata": {
        "id": "3vr8gq9W4Q1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "XBMAi2omzsWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "Understanding Data Distribution: EDA helps identify how data is distributed (e.g., normal, skewed), which informs the choice of appropriate models and transformations.\n",
        "\n",
        "Detecting Outliers and Errors: It allows you to find and address outliers or errors in the data that could skew model performance or lead to incorrect conclusions.\n",
        "\n",
        "Identifying Correlations: EDA reveals correlations between variables, which can guide feature selection and engineering. This helps avoid multicollinearity issues in models.\n",
        "\n",
        "Data Quality Assessment: EDA assesses data completeness and quality, ensuring that models are trained on reliable data.\n",
        "\n",
        "Informing Model Selection: By understanding the data's characteristics, you can choose the most suitable model type (e.g., linear regression for linear relationships).\n",
        "\n",
        "Improving Model Performance: EDA insights can lead to better data preprocessing strategies, such as feature scaling or encoding, which enhance model performance.\n"
      ],
      "metadata": {
        "id": "OcC6x3jR2Z_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.Correlation measures the strength and direction of a linear relationship between two variables. It ranges from -1 perfect negative correlation to 1 perfect positive correlation. A value of 0 indicates no linear relationship Negative correlation occurs when one variable increases as the other decreases.\n",
        "\n",
        " Correlation refers to a statistical relationship between two variables, indicating how closely they move together. It does not imply causation. Correlation can be positive (variables move together), negative (variables move in opposite directions), or zero (no linear relationship)"
      ],
      "metadata": {
        "id": "AXyCRK1p3TME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13."
      ],
      "metadata": {
        "id": "NCBgra_E3bRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.How can you find correlation between variables in Python?\n",
        "\n",
        "Correlation can be calculated using the corr() function from pandas:\n",
        "\n",
        "python\n",
        "import pandas as pd\n",
        "Assuming df is a DataFrame\n",
        "\n",
        "correlation_matrix = df.corr()"
      ],
      "metadata": {
        "id": "hBaAN4iU4XlW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.What is causation? Explain difference between correlation and causation with an example\n",
        "\n",
        "Causation implies that one variable directly affects another.\n",
        "\n",
        "Correlation indicates a statistical relationship but does not imply causation. For example, there might be a correlation between ice cream sales and the number of people wearing shorts, but eating ice cream does not cause people to wear shorts; both are influenced by warmer weather."
      ],
      "metadata": {
        "id": "U5kxJwVq4jcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.What is an Optimizer? What are different types of optimizers? Explain each with an example\n",
        "\n",
        "An optimizer is an algorithm used to minimize the loss function during model training. Common optimizers include:\n",
        "\n",
        "Gradient Descent (GD): Updates parameters based on the gradient of the loss function.\n",
        "\n",
        "Stochastic Gradient Descent (SGD): Uses a single example at a time for updates.\n",
        "\n",
        "Adam Optimizer: Combines GD with adaptive learning rates for each parameter.\n",
        "\n",
        "Example:\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n"
      ],
      "metadata": {
        "id": "h1nkfxA_4sej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.What is sklearn.linear_model?\n",
        "\n",
        "sklearn.linear_model is a module in scikit-learn that provides linear regression models, including ordinary least squares (OLS), ridge regression, and logistic regression."
      ],
      "metadata": {
        "id": "fFQNuSUT8BGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.What does model.fit() do? What arguments must be given?\n",
        "\n",
        "\n",
        "model.fit() trains a model on the provided data. Required arguments typically include the training data (X_train, y_train) and optionally parameters like batch size and epochs.\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "id": "xF1tubt28Kuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.What does model.predict() do? What arguments must be given?\n",
        "The model.predict() method generates predictions using a trained machine learning model. It requires feature data (input variables) in the same format as the training data. For example:\n",
        "\n",
        "\n",
        "X_new = [[feature1, feature2], [feature3, feature4]]\n",
        "predictions = model.predict(X_new)                    \n"
      ],
      "metadata": {
        "id": "ilLvh866zo3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.What is feature scaling? How does it help in Machine Learning?\n",
        "Feature scaling standardizes/normalizes numerical features to a consistent range (e.g., 0–1 or μ=0, σ=1). This prevents models from overemphasizing features with larger magnitudes."
      ],
      "metadata": {
        "id": "PHgoOKH5SLvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.How do we perform scaling in Python?\n",
        "Common Methods:\n",
        "Standardization (Z-score)\n",
        "Transforms data to have mean=0 and standard deviation=1:\n",
        "\n",
        "z\n",
        "=\n",
        "x\n",
        "−\n",
        "μ\n",
        "σ\n",
        "z=\n",
        "σ\n",
        "x−μ\n",
        "\n",
        "Min-Max Scaling\n",
        "Rescales data to a fixed range (e.g., 0–1):\n",
        "\n",
        "x\n",
        "scaled\n",
        "=\n",
        "x\n",
        "−\n",
        "x\n",
        "min\n",
        "⁡\n",
        "x\n",
        "max\n",
        "⁡\n",
        "−\n",
        "x\n",
        "min\n",
        "⁡\n",
        "x\n",
        "scaled\n",
        " =\n",
        "x\n",
        "max\n",
        " −x\n",
        "min\n",
        "\n",
        "x−x\n",
        "min\n",
        "\n"
      ],
      "metadata": {
        "id": "Juo4-nddSdVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.What is sklearn.preprocessing?\n",
        "\n",
        "Scaling: StandardScaler, MinMaxScaler\n",
        "\n",
        "Encoding: Convert categorical data to numbers (e.g., OneHotEncoder)\n",
        "\n",
        "Normalization: Adjust feature distributions"
      ],
      "metadata": {
        "id": "Mi2VoJPTSrT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.How do we split data for model fitting (training and testing) in Python?\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features,\n",
        "    target_variable,\n",
        "    test_size=0.2,  # 20% data for testing\n",
        "    random_state=42 # Reproducibility\n",
        ")\n"
      ],
      "metadata": {
        "id": "KiejTG0yS6cs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.Explain data encoding?\n",
        "Categorical variables are converted to numerical formats for algorithms to process."
      ],
      "metadata": {
        "id": "eTk2zIRES1pF"
      }
    }
  ]
}